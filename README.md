# beAnalytic Case - IDA (Ãndice de Desempenho no Atendimento)

Pipeline ETL para extraÃ§Ã£o, processamento e anÃ¡lise de dados do Ãndice de Desempenho no Atendimento (IDA) de operadoras de telecomunicaÃ§Ãµes do portal ANATEL.

## DescriÃ§Ã£o

Este projeto implementa um pipeline completo de ETL (Extract, Transform, Load) para:
- Extrair arquivos ODS dinamicamente do portal dados.gov.br
- Processar e normalizar dados de desempenho de operadoras
- Carregar dados em Data Mart PostgreSQL
- Gerar anÃ¡lises e visualizaÃ§Ãµes

## Arquitetura

```
projeto_beAnalytic_ida/
â”œâ”€â”€ dados_ida/                      # Arquivos ODS baixados
â”œâ”€â”€ src/                            # Pipeline ETL
â”‚   â”œâ”€â”€ config.py                   # ConfiguraÃ§Ãµes
â”‚   â”œâ”€â”€ loader.py                   # Carregador PostgreSQL
â”‚   â”œâ”€â”€ main.py                     # Pipeline principal
â”‚   â””â”€â”€ ods_processor.py            # Processador de ODS
â”œâ”€â”€ sql/                            # Scripts SQL do Data Mart
â”‚   â”œâ”€â”€ 01_create_schema.sql
â”‚   â”œâ”€â”€ 02_create_dimensions.sql
â”‚   â”œâ”€â”€ 03_create_fato.sql
â”‚   â””â”€â”€ 04_create_views.sql
â”œâ”€â”€ baixar_dinamico.py              # Extrator dinÃ¢mico (web scraping)
â”œâ”€â”€ processar_ods.py                # Processador standalone
â”œâ”€â”€ docker-compose.yml              # PostgreSQL setup
â””â”€â”€ requirements.txt                # DependÃªncias Python
```

## ğŸš€ Tecnologias

- **Python 3.12+**
- **Playwright** - Web scraping
- **Pandas** - Processamento de dados
- **PostgreSQL** - Data Mart
- **Docker** - ContainerizaÃ§Ã£o

## ğŸ“¦ InstalaÃ§Ã£o

```bash
# Clonar repositÃ³rio
git clone https://github.com/euvanessa-prado/beanalytic_case_ida.git
cd beanalytic_case_ida

# Instalar dependÃªncias
pip install -r requirements.txt

# Instalar Playwright
playwright install chromium
```

## ğŸ¯ Uso

### 1. Extrair dados do portal

```bash
python baixar_dinamico.py
```

Extrai dinamicamente arquivos ODS do portal dados.gov.br (19 arquivos: SCM, SMP, STFC de 2013-2019).

### 2. Processar dados

```bash
python processar_ods.py
```

Processa e normaliza 14.749 registros de 29 operadoras.

### 3. Carregar no PostgreSQL

```bash
# Iniciar PostgreSQL
docker-compose up -d

# Executar pipeline ETL
python src/main.py
```

## ğŸ“Š Dados

- **PerÃ­odo**: 2013-2019
- **Registros**: 14.749
- **Operadoras**: 29 (OI, TIM, VIVO, CLARO, etc.)
- **ServiÃ§os**: SCM (Banda Larga), SMP (MÃ³vel), STFC (Fixo)

## ğŸ›ï¸ Data Mart

### DimensÃµes
- `dim_tempo` - PerÃ­odos temporais
- `dim_grupo_economico` - Operadoras
- `dim_servico` - Tipos de serviÃ§o
- `dim_regiao` - RegiÃµes/UF

### Fato
- `fato_ida` - MÃ©tricas de desempenho

### Views
- `vw_taxa_variacao_mensal` - AnÃ¡lise de variaÃ§Ã£o mensal

## ğŸ¨ PadrÃµes de CÃ³digo

- âœ… OrientaÃ§Ã£o a Objetos (OOP)
- âœ… DocumentaÃ§Ã£o pydoc completa
- âœ… Type hints (Python 3.6+)
- âœ… SeparaÃ§Ã£o de responsabilidades
- âœ… Clean Code

## ğŸ“ Classes Principais

### baixar_dinamico.py
- `RecursoPortal` - Representa recurso do portal
- `PortalExtractor` - Extrator web scraping
- `ODSDownloader` - Gerenciador de downloads
- `AnatelScraper` - Orquestrador principal

### src/ods_processor.py
- `DataNormalizer` - Normalizador de dados
- `ODSProcessor` - Processador de arquivos ODS

### src/loader.py
- `DatabaseConnection` - Gerenciador de conexÃ£o
- `DimensionLoader` - Carregador de dimensÃµes
- `FactLoader` - Carregador de fatos
- `DataLoader` - Orquestrador de carga

## ğŸ”§ ConfiguraÃ§Ã£o

VariÃ¡veis de ambiente (opcional):

```bash
DB_HOST=localhost
DB_PORT=5432
DB_NAME=ida_datamart
DB_USER=postgres
DB_PASSWORD=postgres
DATA_DIR=dados_ida
```

## ğŸ“ˆ Resultados

- 19 arquivos ODS extraÃ­dos automaticamente
- 14.749 registros processados e normalizados
- Data Mart dimensional implementado
- Pipeline ETL completo e funcional

## ğŸ‘¥ Autor

Vanessa Prado

## ğŸ“„ LicenÃ§a

Este projeto foi desenvolvido como case tÃ©cnico para beAnalytic.
