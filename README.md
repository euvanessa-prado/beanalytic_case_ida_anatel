# Case T√©cnico: Data Mart IDA Anatel

## Vis√£o Geral
Este projeto implementa uma solu√ß√£o de Engenharia de Dados ponta a ponta para a ingest√£o, tratamento e modelagem anal√≠tica dos dados do **√çndice de Desempenho no Atendimento (IDA)** da Anatel. A solu√ß√£o automatiza a extra√ß√£o de arquivos OpenDocument (.ods), normaliza estruturas variadas atrav√©s de processamento Python e consolida as m√©tricas em um Data Mart PostgreSQL seguindo o modelo dimensional (Star Schema).

### M√©tricas Principais
- **Taxa de Varia√ß√£o Individual**: Evolu√ß√£o percentual do IDA de uma operadora.
- **Benchmarking de Mercado**: Compara√ß√£o da varia√ß√£o individual contra a m√©dia do setor.
- **M√©trica de Agilidade**: Taxa de resolvidas em at√© 5 dias √∫teis.

## Arquitetura da Solu√ß√£o

```mermaid
graph TD
    %% Styles
    classDef source fill:#e1f5fe,stroke:#01579b,stroke-width:2px;
    classDef process fill:#fff9c4,stroke:#fbc02d,stroke-width:2px;
    classDef db fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px;
    classDef viz fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px;

    %% Source
    subgraph Origem ["üìÇ Origem"]
        ODS[("üìÑ Arquivos .ods<br/>(dados_ida/)")]:::source
    end

    %% Ingestion Layer
    subgraph Ingestao ["‚öôÔ∏è Camada de Ingest√£o (Python)"]
        Processor["üêç ODS Processor<br/>(Pandas/Polars)"]:::process
        Loader["üöö Bulk Loader<br/>(psycopg2)"]:::process
    end

    %% Data Layer
    subgraph Dados ["üóÑÔ∏è Camada de Dados (PostgreSQL)"]
        Staging[("üì• Staging Area<br/>(Tabelas Brutas)")]:::db
        StarSchema[("‚≠ê Star Schema<br/>(Dimens√µes & Fatos)")]:::db
        Views[("üìä Views Anal√≠ticas<br/>(KPIs & Pivots)")]:::db
    end

    %% Analytics Layer
    subgraph Analitico ["üìà Camada Anal√≠tica"]
        Streamlit["üñ•Ô∏è Streamlit Dashboard<br/>(Visualiza√ß√£o Interativa)"]:::viz
    end

    %% Relationships
    ODS --> Processor
    Processor --> Loader
    Loader --> Staging
    Staging -->|SQL Transform| StarSchema
    StarSchema -->|SQL Logic| Views
    Views -->|Query| Streamlit
```

### 1. Camada de Ingest√£o (Python + Polars)
- **ODS Processor**: Motor modernizado que utiliza `pandas`/`odfpy` para leitura inicial e **Polars** para transforma√ß√£o massiva.
- **Parquet Cache**: Implementa√ß√£o de cache local em formato **Parquet** para acelerar reprocessamentos.
- **Normaliza√ß√£o**: Convers√£o eficiente de tabelas wide para long format usando a engine Rust do Polars.
- **Bulk Loading**: Persist√™ncia otimizada na Staging via `psycopg2.extras.execute_values`.

### 2. Camada de Dados (PostgreSQL)
- **Staging**: Camada tempor√°ria para persist√™ncia dos dados brutos normalizados.
- **Trusted/Refined (Dimensional)**:
    - `dim_tempo`: Dimens√£o temporal com atributos de calend√°rio.
    - `dim_grupo_economico`: Cadastro √∫nico de operadoras.
    - `dim_servico`: Classifica√ß√£o dos servi√ßos de telecomunica√ß√£o.
    - `fato_ida`: Tabela fato contendo m√©tricas de agilidade (5 dias), resolu√ß√£o total e volumes de solicita√ß√µes.

### 3. Camada Anal√≠tica (SQL)
- **View Pivotada**: Implementa√ß√£o de SQL din√¢mico para gerar relat√≥rios de varia√ß√£o percentual m√™s a m√™s, permitindo compara√ß√£o direta entre o desempenho individual das operadoras e a m√©dia do mercado.
- **Dashboard Interativo**: Interface gr√°fica desenvolvida em **Streamlit** para visualiza√ß√£o amig√°vel dos dados, permitindo an√°lises de tend√™ncia e heatmaps comparativos.

## Estrutura do Projeto
- `/sql`: Scripts de DDL, Transforma√ß√£o e Views.
- `/src`: M√≥dulos Python (Normaliza√ß√£o e Carregamento).
- `/dados_ida`: Reposit√≥rio de arquivos brutos (.ods).
- `docker-compose.yml`: Orquestra√ß√£o da infraestrutura.
- `/assets`: Recursos gr√°ficos do dashboard.

## Ferramentas e Bibliotecas
- Linguagem: Python 3.11.12
- Banco: PostgreSQL 17.5
- Orquestra√ß√£o: Docker Compose
- Frontend: Streamlit
- Visualiza√ß√£o: Plotly
- Bibliotecas Python:
  - **polars** (processamento de dados de alta performance)
  - pandas, odfpy (leitura de ODS)
  - psycopg2-binary (PostgreSQL)
  - python-dotenv (configura√ß√£o)
  - plotly (visualiza√ß√£o de dados)
  - streamlit (interface web)
  - requests (requisi√ß√µes HTTP)

## Execu√ß√£o

A solu√ß√£o √© totalmente conteinerizada via Docker. Siga os passos abaixo:

1. **Pr√©-requisitos**:
   - Docker e Docker Compose instalados.

2. **Subir tudo (um comando)**:
   ```bash
   docker compose up -d --build
   ```
   - O par√¢metro `--build` garante que qualquer altera√ß√£o recente no c√≥digo seja incorporada √† imagem.
   - As configura√ß√µes usam valores padr√£o seguros (banco local), mas podem ser sobrescritas via `.env` se necess√°rio.
   - Ap√≥s remover volumes (reset), os dados s√£o recarregados automaticamente pelo ETL.

3. **Acesso e Credenciais**:
   - **Dashboard (Streamlit)**: [http://localhost:8501](http://localhost:8501)
   - **Banco de Dados (PostgreSQL)**:
     - **Host**: `localhost` (porta 5432)
     - **Database**: `ida_datamart`
     - **User**: `postgres`
     - **Password**: `postgres`
   - **Administra√ß√£o (PgAdmin)**:
     - **Link**: [http://localhost:5050](http://localhost:5050)
     - **Email**: `admin@admin.com`
     - **Senha**: `admin`
     - *Dica: Para conectar ao banco no PgAdmin, use o host `postgres` (nome do container).*
   - **Conex√£o Externa (DBeaver/PowerBI)**:
     - Utilize as mesmas credenciais do PostgreSQL acima. O host √© `localhost` pois a porta 5432 est√° exposta.
   
   > **Nota para o Avaliador:** As credenciais s√£o padr√£o (`postgres`/`postgres`) para facilitar a execu√ß√£o local do teste t√©cnico. Em produ√ß√£o, utilizar√≠amos vari√°veis de ambiente seguras (Secrets).

4. **Fluxo Autom√°tico**:
   - O banco PostgreSQL √© inicializado com o schema base.
   - O container `data_loader` aguarda o banco estar `healthy`.
   - Inicia o processamento dos arquivos presentes em `dados_ida/`.
   - Executa as transforma√ß√µes SQL para carga da Fato e cria√ß√£o das Views:
     - [01_transform_load.sql](sql/01_transform_load.sql)
    - [view_taxa_resolucao_5_dias.sql](sql/view_taxa_resolucao_5_dias.sql)

5. **Ver logs rapidamente**:
   ```bash
   docker compose logs -f data_loader
   ```
   - Aguarde a mensagem: `ETL conclu√≠do com sucesso`.

6. **Reset opcional (apagar dados e subir limpo)**:
   ```bash
   docker compose down -v && docker compose up -d
   ```
   - O ETL recria o Data Mart automaticamente.

## üß≠ Detalhes do ETL

### Passo a Passo
- Ler ODS de `dados_ida/` e normalizar para long-format: [ods_processor.py](src/ods_processor.py)
- Carregar em lote para `ida.staging_ida`: [staging_loader.py](src/staging_loader.py)
- Consolidar dimens√µes e fato: [01_transform_load.sql](sql/01_transform_load.sql)
- Construir view de varia√ß√£o pivoteada: [view_taxa_resolucao_5_dias.sql](sql/view_taxa_resolucao_5_dias.sql)
- Exibir no dashboard (tema escuro, filtros na lateral, KPIs din√¢micos): [dashboard.py](src/dashboard.py)

### üìú Sequ√™ncia dos Scripts
1. Inicializa√ß√£o do schema e tabelas:
   - [00_init_completo.sql](sql/00_init_completo.sql)
2. Transforma√ß√£o e carga para o modelo estrela:
   - [01_transform_load.sql](sql/01_transform_load.sql)
3. Camada anal√≠tica (view com varia√ß√£o e piv√¥):
   - [view_taxa_resolucao_5_dias.sql](sql/view_taxa_resolucao_5_dias.sql)
4. Orquestra√ß√£o e chamada dos scripts (Python):
   - [carregar_dados_no_postgres.py](carregar_dados_no_postgres.py#L42-L99)

## ÔøΩ Valida√ß√µes e Troubleshooting

### Valida√ß√µes √öteis
- Contagens r√°pidas (ap√≥s carga):
  ```bash
  docker compose exec postgres psql -U postgres -d ida_datamart -c "SELECT COUNT(*) FROM ida.fato_ida;"
  docker compose exec postgres psql -U postgres -d ida_datamart -c "SELECT COUNT(*) FROM ida.view_taxa_resolucao_5_dias;"
  ```

### Troubleshooting
- Mensagem ‚ÄúInicializa√ß√£o em andamento‚Äù no dashboard:
  - O ETL ainda est√° criando a view; aguarde ‚ÄúETL completed successfully‚Äù nos logs e recarregue a p√°gina.
- Reconstruir tudo do zero:
  - `docker compose down -v && docker compose up -d`
- Logs do ETL:
  - `docker compose logs -f data_loader`

## Objetos de Avalia√ß√£o (Prova T√©cnica)
- O projeto roda integralmente com `docker compose up` (infra + ETL + dashboard).
- SQL: organiza√ß√£o, clareza e documenta√ß√£o usando `COMMENT ON`.
- Python: organiza√ß√£o, clareza, docstrings (pydoc) e uso de OOP.
- Sem depend√™ncia de scripts externos; instru√ß√µes m√≠nimas e diretas.

## ‚úÖ Roadmap de Profissionaliza√ß√£o
- Opcional: integrar dbt para materializar dim/fato/view com testes e documenta√ß√£o.
- Adicionar CI com lint/testes de import (GitHub Actions).

## Transforma√ß√µes com dbt (opcional)
- Projeto dbt inclu√≠do em `/dbt` (models para dim_tempo, dim_grupo_economico, dim_servico e fato_ida).
- Executar dbt via Compose perfil ‚Äúanalytics‚Äù:
  ```bash
  docker compose --profile analytics up dbt
  ```
  ou em execu√ß√£o pontual:
  ```bash
  docker compose run --rm dbt bash -lc "dbt run && dbt test"
  ```
- Conex√£o configurada em `/dbt/profiles.yml` para o Postgres do Compose.
- Modelo anal√≠tico ‚Äúlong_delta‚Äù para varia√ß√£o mensal e diferen√ßa (mercado vs individual).
